input {
  file {
    type => "weblogic_domainlog"
    path => [ "/media/sf_log/domain/*.log*"]
    start_position => beginning
  	sincedb_path => "/dev/null"
  }
  file {
    type => "weblogic_diagnostic"
    path => [ "/media/sf_log/diag/*.log"]
    start_position => beginning
    sincedb_path => "/dev/null"
  }
  file {
    type => "ADMout"
    path => [ "/media/sf_log/out/*.out"]
    start_position => beginning
    exclude => ["*.tmp", "*part*"]
    sincedb_path => "/dev/null"
  }
  file {
    type => "Accesslog"
    path => [ "/media/sf_log/access/*.log"] 
    start_position => beginning
    exclude => ["*.tmp", "*part*"]
    sincedb_path => "/dev/null"
  }
}
filter {
 ## WebLogic Server Http Access Log 
  if [type] == "Accesslog" { 
    grok { 
      match => [ "message", "\A%{IP:request_ip} - %{USER:user} %{SYSLOG5424SD:access_timestamp} %{QUOTEDSTRING:uri} %{INT:response} %{NUMBER:time_taken}"]
	  patterns_dir => "./patterns"
    } 
#    if [path] == "/fmw/log/domains/soa_ont_domain/AdminServer/access.log"{
#       mutate { add_field => { "managed_server" => "AdminServer"} }
#    } else if [path] == "/fmw/log/domains/soa_ont_domain/AdminServer/access.log"{
#       mutate { add_field => { "managed_server" => "soa_ont_ms1"} }
#    } else if [path] == "/fmw/log/domains/soa_ont_domain/AdminServer/access.log"{
#       mutate { add_field => { "managed_server" => "osb_ont_ms1"} }
#    } 
    mutate { add_field => { "[@metadata][index]" => "logstash-access-%{+YYYY.MM.dd}" } }
    mutate { convert => { "response" => "integer" }}
    mutate { convert => { "time_taken" => "integer" }}
  } else if [type] == "weblogic_domainlog"
  {
    multiline {
      pattern => "^####"
      negate => true
      what => "previous"
    }
    grok {
      match => { "message" => "####<%{DATA:wls_timestamp}> <%{WORD:severity}> <%{DATA:wls_topic}> <%{IPORHOST:hostname}> <(%{WORD:server})?> %{GREEDYDATA:log_message}"}
      add_field => ["Log", "Admin Domain Log"]
      add_field => ["thread_status", "OK"]
	  patterns_dir => "./patterns"
    }
    date {
      locale => en
      match =>[ "wls_timestamp"
              , "MMM d, yyyy h:mm:ss a 'CET'"
              , "MMM d, yyyy h:mm:ss a 'CEST'"
              , "MMM d, yyyy h:mm:ss a z"
              , "MMM d, yyyy h:mm:ss a zzz"
			  , "ISO8601"
			  ]
    }
    ruby {
          code => "
		      begin
			    fieldArray = event['log_message'].split('> <')
				int i=0
                for field in fieldArray
					i = i+1
                    field = field.delete '<'
                    field = field.delete '>'
                    event['field_'+i] = field
                end
			  rescue
			  end
          "
    }	
    mutate { add_field => { "[@metadata][index]" => "logstash-wl_domain-%{+YYYY.MM.dd}" } }	
  } else if [type] == "ADMout" 
  {
    multiline {
      pattern => "^<(Jan|Feb|Mar|Apr|May|Jun|Jul|Aug|Sep|Oct|Nov|Dec)"
      negate => true
      what => "previous"
    }
    grok {
      match => { "message" => "<%{DATA:wls_timestamp}> <%{WORD:severity}> <%{DATA:wls_topic}> <%{DATA:log_code}>%{GREEDYDATA:log_message}"}
      add_field => ["Log", "ADMout"]
      add_field => ["thread_status", "OK"]
	  patterns_dir => "./patterns"
    }
    date {
      locale => en
      match =>  [ "wls_timestamp"
                , "MMM d, yyyy h:mm:ss a 'CET'"
                , "MMM d, yyyy h:mm:ss a 'CEST'"
                , "MMM d, yyyy h:mm:ss a"
                , "MMM d, yyyy h:mm:ss a z"
                , "MMM d, yyyy h:mm:ss a zzz"
    		    , "ISO8601"
                ]
    }
    mutate {
      # cosmetic unification
      uppercase => [ "severity" ]
    }
    mutate { add_field => { "[@metadata][index]" => "logstash-wl_out-%{+YYYY.MM.dd}" } }
  } else if [type] == "weblogic_diagnostic" {
    multiline {
      pattern => "^\["
      negate => true
      what => "previous"
    }
    grok {
      match => { "message" => "^\[%{DATA:wls_timestamp}\]\s?\[%{WORD:managed_server}\]\s?\[%{DATA:severity}\]\s?\[%{DATA:log_code}\]\s?\[%{DATA:log_component}\]%{GREEDYDATA:log_message}"}
      add_field => ["Log", "ADMDiagnostic"]
      add_field => ["thread_status", "OK"]
	  patterns_dir => "./patterns"
    }
    date {
      locale => en
      match =>  [ "wls_timestamp"
                , "ISO8601"
                , "yyyy-MM-dd'T'H:mm:ss.SSSZZ"
                , "yyyy-MM-dd'T'HH:mm:ss.SSSZZ"
                , "yyyy-MM-dd'T'h:mm:ss.SSSZZ"
                , "MMM d, yyyy h:mm:ss a 'CET'"
                , "MMM d, yyyy h:mm:ss a 'CEST'"
                , "MM d, yyyy h:mm:ss a 'CET'"
                , "MMM d, yyyy h:mm:ss a"				
                , "MMM d, yyyy h:mm:ss a z"
                , "MMM d, yyyy h:mm:ss a zzz"
                ]
    }
    mutate {
      uppercase => [ "severity" ]
    }
    ruby {
          code => "
		      begin
			    fieldArray = event['log_message'].split('] [')
                for field in fieldArray
                    field = field.delete '['
                    field = field.delete ']'
                    result = field.split(': ')
                    event[result[0]] = result[1]
                end
			  rescue
			  end
          "
    }
	ruby {
        code => "
          event.to_hash.keys.each { |k| event[ k.sub('.','_') ] = event.remove(k) if k.include?'.' }
          event.to_hash.keys.each { |k| event[ k.sub('.','_') ] = event.remove(k) if k.include?'.' }
          event.to_hash.keys.each { |k| event[ k.sub('.','_') ] = event.remove(k) if k.include?'.' }
          event.to_hash.keys.each { |k| event[ k.sub('.','_') ] = event.remove(k) if k.include?'.' }
          event.to_hash.keys.each { |k| event[ k.sub('.','_') ] = event.remove(k) if k.include?'.' }
          event.to_hash.keys.each { |k| event[ k.sub('.','_') ] = event.remove(k) if k.include?'.' }
          event.to_hash.keys.each { |k| event[ k.sub('.','_') ] = event.remove(k) if k.include?'.' }
          event.to_hash.keys.each { |k| event[ k.sub('.','_') ] = event.remove(k) if k.include?'.' }
          event.to_hash.keys.each { |k| event[ k.sub('.','_') ] = event.remove(k) if k.include?'.' }
        "
    }
    mutate { add_field => { "[@metadata][index]" => "logstash-weblogic_diag-%{+YYYY.MM.dd}" } }
  }
  if [message] {
    ruby {
      init => "require 'digest/sha1'"
      code => "event['@metadata']['id'] = Digest::SHA1.base64digest(event['message'])"
    }
  }  
  if "BEA-" in [message] {
    mutate {
      add_tag => ["bea-error"]
    }
  }
  if "BEA-" in [message] {
    mutate {
      add_tag => ["bea-error"]
    }
  }
  if "XML-" in [message] {
    mutate {
      add_tag => ["xml-error"]
    }
  }
  if "ORA-20000" in [message] {
    mutate {
      add_tag => ["ORA-20000"]
    }
  }
  if "JCA-" in [message] {
    mutate {
      add_tag => ["jca-error"]
    }
  }
  if "ORA-24756" in [message] {
    mutate {
      add_tag => ["ORA-24756"]
    }
  }
  if "BEA-000337" in [message] {
    mutate {
      add_tag => ["stuck_thread"]
    }
    mutate {
      replace => ["thread_status", "STUCK" ]
    }
  }
  if "BEA-000339" in [message] {
    mutate {
      add_tag => ["unstuck_thread"]
    }
    mutate {
      replace => ["thread_status", "UNSTUCK" ]
    }
  }
  mutate{
    remove_tag => ["multiline"]
  }
}
output {
  elasticsearch {   
    index => "%{[@metadata][index]}"
    hosts => ["localhost:9200"]
    document_id => "%{[@metadata][id]}"
  }
}
